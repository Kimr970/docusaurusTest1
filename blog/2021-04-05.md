---
title: Faction Data Lake Blog
author: Kread 
author_title: Faction Blog test
[//]: # This syntax work author_image_url: https://my-website/img/kim.jpg
author_image_url: '/img/kim.jpg'
tags: [First | Blog | test]
---
Data Lakes 
Let’s first dive into why Data Lakes came into fruition in the first place.  The proliferation and excitement around Data Lakes manifested primarily because of these 4 reasons:
	1).  Provide the Single-Source-Of-The-Truth for an Enterprise
	2).  Ingest and Process any kind of data (structured, semi-structured, unstructured)
	3).  Ability to process terabytes to petabytes of data
	4).  The ability to use commodity hardware
Data Lakes can process petabytes of data quickly, they can support near real time requirements, they are very flexible, and they perform at scale if they are architected and maintained correctly. However, there are some shortcomings to Data Lakes as well.  First, while Data Lakes predominately are Hadoop based, the performance of querying data on a data lake is not always performant.  There are multiple simultaneous workloads running on the platform e.g., ETL/ELT processing jobs, streaming jobs, batch jobs and reporting and queries.  Utilizing Impala, Hive or HBASE on the Data Lake for analysis and reporting didn’t provide the needed business logic and decisions capabilities that needed to still be performed.  Further, data needs to be bucketed, table statistics need to be updated, partioning needs to exist and small files are still very problematic on Data Lakes.   I often compare Data Lakes to oil refineries, because for some strange reason, people resonate better understanding with oil refineries than they do a data lake.  Consider this, Oil Refineries bring in crude oil.  Data Lakes bring in Raw Data (directly from the source).  That raw data is immediately catalogued, saved by data (and processing can be replayed at any time in the future should it be needed).  Like an Oil Refinery, where the raw crude oil is cleaned and chemicals are added, the data lake takes the data, cleans it, (believe it not, data is not always clean coming into the data lake), checks for duplicates, anomalies, data validation routines, and then combines it with other data such as metadata, master data, maybe there are other data that is joined with it as well and then made available for consumption or feeding to other systems.  Just as an oil refinery makes different products and distributes those products such as oil, kerosene, gasoline to gas stations, other stores, etc., for consumption.
Second, while Data Lakes did use commodity hardware, the solution can actually be very expensive.   With some of the earlier Hadoop architectures and physical hardware we were not able to separate compute from storage.  And thus, the scalability of the solution was wrought with problems in that you could not scale Storage and Compute independently, which meant that you would often see a cluster that had way too much storage vs. compute or vis-a-vis.  As Hardware and Data lake technology progressed, storage and compute could be separated, and this helped the scalability dilemma.  But Hadoop proved to be not a cheap solution at all.  Petabytes of storage and always the need for more storage was always a hassle because 1). Data was growing faster than original estimates 2).  Additional Data Sources were added 3).  New projects initiated need for more storage and more compute.  Because of these continuing changes and requirements, the demand for storage kept increasing while the supply of hardware (storage in this case) was always getting bogged down in corporate budget bureaucracies.  So, then the question became why can’t I just move my data lake to the public cloud where you can have access to all the storage (hot and cold) you could ever want and ability to elastically scale on demand?  I think for many companies moving to cloud makes perfect sense.  However, there are MANY companies that don’t move to public cloud because of security concerns and vendor-lock in.  Both security and vendor-lock concerns were the predominant issues that I faced with my former company.  Cyber Security would not permit any public cloud presence for data nor did the company want to get “saddled” with a cloud vendor that held us hostage (multi-year licenses, stagnation of tool). 

